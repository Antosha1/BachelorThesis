{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 7500 sentences with 8935 annotations.\n",
      "Val: 2500 sentences with 2987 annotations.\n"
     ]
    }
   ],
   "source": [
    "train_annotations_path = '../data/Genes/GENETAG/train/Gold.format'\n",
    "val_annotations_path = '../data/Genes/GENETAG/test/Gold.format'\n",
    "\n",
    "train_data_path = '../data/Genes/GENETAG/train/TAGGED_GENE_CORPUS'\n",
    "val_data_path = '../data/Genes/GENETAG/test/TAGGED_GENE_CORPUS'\n",
    "\n",
    "################################################################\n",
    "\n",
    "with open(train_annotations_path, 'r') as file:\n",
    "    train_annotations = [row.strip() for row in file]\n",
    "    \n",
    "with open(val_annotations_path, 'r') as file:\n",
    "    val_annotations = [row.strip() for row in file]\n",
    "\n",
    "################################################################    \n",
    "\n",
    "train_data, val_data = [], []\n",
    "\n",
    "for sentence in open(train_data_path).read().split('\\n'):\n",
    "    train_data.append(sentence)\n",
    "\n",
    "for sentence in open(val_data_path).read().split('\\n'):\n",
    "    val_data.append(sentence)\n",
    "    \n",
    "train_data.remove(train_data[-1])\n",
    "val_data.remove(val_data[-1])\n",
    "    \n",
    "print('Train: {} sentences with {} annotations.'.format(len(train_data), len(train_annotations)))\n",
    "print('Val: {} sentences with {} annotations.'.format(len(val_data), len(val_annotations)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning_data(data):\n",
    "    dict_data = {}\n",
    "    \n",
    "    for sentence in data:\n",
    "        clean = []\n",
    "        for token in sentence.split():\n",
    "            clear_token = []\n",
    "            if '/' not in token:\n",
    "                clean.append(token)\n",
    "            else:\n",
    "                for symb in token:\n",
    "                    if symb != '/':\n",
    "                        clear_token.append(symb)\n",
    "                    else:\n",
    "                        break\n",
    "                clean.append(''.join(clear_token))\n",
    "                key, clear_sentence = clean[0], ' '.join(clean[1:])\n",
    "                dict_data[key] = clear_sentence\n",
    "    return dict_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_train = cleaning_data(train_data)\n",
    "dict_val = cleaning_data(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_conll_format(dict_data, annotations, data_split):\n",
    "    \n",
    "    file_name = r'genetag_' + data_split + '_1.txt'\n",
    "    with open(file_name, 'w') as file:\n",
    "        for sent_idx, sent in dict_data.items():\n",
    "            gene_pos = []\n",
    "            for annotation in annotations:\n",
    "                if sent_idx in annotation.split('|'):\n",
    "                    gene_pos.append([int(a) for a in annotation.split('|')[1].split()])\n",
    "            gene_pos.sort(key=itemgetter(0))\n",
    "            \n",
    "            for idx, token in enumerate(sent.split()):\n",
    "                flag = 0\n",
    "                for pos in gene_pos:\n",
    "                    if idx in range(pos[0], pos[1]+1):\n",
    "                        if (idx == pos[0]):\n",
    "                            flag = 1\n",
    "                            file.write(token + ' ' + 'B-GENE' + '\\n')\n",
    "                            break\n",
    "                        elif (idx in range(pos[0], pos[1]+1)):\n",
    "                            flag = 1\n",
    "                            file.write(token + ' ' + 'I-GENE' + '\\n')\n",
    "                            break\n",
    "                if (flag == 0):\n",
    "                    file.write(token + ' ' + 'O' + '\\n')\n",
    "            file.write('\\n')\n",
    "            \n",
    "\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 36.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "to_conll_format(dict_train, train_annotations, data_split='train')\n",
    "to_conll_format(dict_val, val_annotations, data_split='val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
